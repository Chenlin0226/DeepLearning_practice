{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot is not perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Data_n_ModelBase2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# options\n",
    "cell_type_ = ['RNN','LSTM','GRU']\n",
    "epochs_ = [100]\n",
    "nb_hidden_layers_ = [ 1, 2 ]\n",
    "nb_hidden_units_ = [100, 200, 300]\n",
    "learning_rate_ = [ 0.005, 0.001 ]\n",
    "batch_size_ = [ 32, 128 ]\n",
    "\n",
    "args_ = [ args(ct,e,ly,un,lr,bs) for ct in cell_type_ \n",
    "         for e in epochs_ for ly in nb_hidden_layers_ for un in nb_hidden_units_\n",
    "         for lr in learning_rate_ for bs in batch_size_ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spend 50 min\n"
     ]
    }
   ],
   "source": [
    "print 'Spend '+ str(args_[i].epochs*30/60) + ' min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cell_type', 'RNN')\n",
      "('epochs', 100)\n",
      "('nb_hidden_layers', 1)\n",
      "('nb_hidden_units', 100)\n",
      "('learning_rate', 0.005)\n",
      "('batch_size', 32)\n"
     ]
    }
   ],
   "source": [
    "args_[i].print_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create a new folder: ./Model_1 !!\n",
      "create a new model: Model_1 !!\n",
      "('cell_type', 'RNN')\n",
      "('epochs', 100)\n",
      "('nb_hidden_layers', 1)\n",
      "('nb_hidden_units', 100)\n",
      "('learning_rate', 0.005)\n",
      "('batch_size', 32)\n",
      "epo: 0, train_loss: 0.406009, train_acc: 0.81354\n",
      "epo: 0, test_loss: 0.280501, test_acc: 0.88776\n",
      "epo: 1, train_loss: 0.287805, train_acc: 0.882122\n",
      "epo: 1, test_loss: 0.257149, test_acc: 0.901241\n",
      "epo: 2, train_loss: 0.2626, train_acc: 0.894406\n",
      "epo: 2, test_loss: 0.229407, test_acc: 0.911241\n",
      "epo: 3, train_loss: 0.237863, train_acc: 0.903809\n",
      "epo: 3, test_loss: 0.206312, test_acc: 0.92316\n",
      "epo: 4, train_loss: 0.21933, train_acc: 0.910291\n",
      "epo: 4, test_loss: 0.189821, test_acc: 0.930121\n",
      "epo: 5, train_loss: 0.212502, train_acc: 0.913052\n",
      "epo: 5, test_loss: 0.180887, test_acc: 0.933401\n",
      "epo: 6, train_loss: 0.195007, train_acc: 0.921215\n",
      "epo: 6, test_loss: 0.17783, test_acc: 0.933481\n",
      "epo: 7, train_loss: 0.18701, train_acc: 0.925776\n",
      "epo: 7, test_loss: 0.166178, test_acc: 0.937841\n",
      "epo: 8, train_loss: 0.180135, train_acc: 0.928337\n",
      "epo: 8, test_loss: 0.162395, test_acc: 0.939921\n",
      "epo: 9, train_loss: 0.182282, train_acc: 0.928017\n",
      "epo: 9, test_loss: 0.154034, test_acc: 0.942521\n",
      "epo: 10, train_loss: 0.170188, train_acc: 0.932458\n",
      "epo: 10, test_loss: 0.155537, test_acc: 0.942761\n",
      "epo: 11, train_loss: 0.171868, train_acc: 0.930818\n",
      "epo: 11, test_loss: 0.150952, test_acc: 0.943721\n",
      "epo: 12, train_loss: 0.167569, train_acc: 0.932618\n",
      "epo: 12, test_loss: 0.149641, test_acc: 0.944761\n",
      "epo: 13, train_loss: 0.167435, train_acc: 0.933499\n",
      "epo: 13, test_loss: 0.145424, test_acc: 0.946601\n",
      "epo: 14, train_loss: 0.166736, train_acc: 0.934139\n",
      "epo: 14, test_loss: 0.145196, test_acc: 0.947361\n",
      "epo: 15, train_loss: 0.169364, train_acc: 0.932738\n",
      "epo: 15, test_loss: 0.139463, test_acc: 0.947761\n",
      "epo: 16, train_loss: 0.165965, train_acc: 0.934379\n",
      "epo: 16, test_loss: 0.144011, test_acc: 0.947961\n",
      "epo: 17, train_loss: 0.162968, train_acc: 0.935499\n",
      "epo: 17, test_loss: 0.141919, test_acc: 0.948921\n",
      "epo: 18, train_loss: 0.160237, train_acc: 0.93746\n",
      "epo: 18, test_loss: 0.139743, test_acc: 0.949641\n",
      "epo: 19, train_loss: 0.161764, train_acc: 0.93678\n",
      "epo: 19, test_loss: 0.154171, test_acc: 0.943401\n",
      "epo: 20, train_loss: 0.159535, train_acc: 0.93722\n",
      "epo: 20, test_loss: 0.141522, test_acc: 0.949561\n",
      "epo: 21, train_loss: 0.156403, train_acc: 0.9389\n",
      "epo: 21, test_loss: 0.136334, test_acc: 0.951121\n",
      "epo: 22, train_loss: 0.155507, train_acc: 0.939101\n",
      "epo: 22, test_loss: 0.13803, test_acc: 0.950801\n",
      "epo: 23, train_loss: 0.158622, train_acc: 0.93778\n",
      "epo: 23, test_loss: 0.143386, test_acc: 0.948641\n",
      "epo: 24, train_loss: 0.156456, train_acc: 0.93822\n",
      "epo: 24, test_loss: 0.144133, test_acc: 0.948441\n",
      "epo: 25, train_loss: 0.158533, train_acc: 0.93726\n",
      "epo: 25, test_loss: 0.144889, test_acc: 0.948441\n",
      "epo: 26, train_loss: 0.156798, train_acc: 0.9385\n",
      "epo: 26, test_loss: 0.141792, test_acc: 0.949801\n",
      "epo: 27, train_loss: 0.157253, train_acc: 0.93722\n",
      "epo: 27, test_loss: 0.136742, test_acc: 0.951321\n",
      "epo: 28, train_loss: 0.153594, train_acc: 0.939061\n",
      "epo: 28, test_loss: 0.139253, test_acc: 0.950761\n",
      "epo: 29, train_loss: 0.146517, train_acc: 0.942622\n",
      "epo: 29, test_loss: 0.139163, test_acc: 0.950561\n",
      "epo: 30, train_loss: 0.151743, train_acc: 0.940741\n",
      "epo: 30, test_loss: 0.141172, test_acc: 0.949921\n",
      "epo: 31, train_loss: 0.148958, train_acc: 0.941501\n",
      "epo: 31, test_loss: 0.143969, test_acc: 0.948921\n",
      "epo: 32, train_loss: 0.145081, train_acc: 0.943422\n",
      "epo: 32, test_loss: 0.138823, test_acc: 0.950201\n",
      "epo: 33, train_loss: 0.145728, train_acc: 0.943302\n",
      "epo: 33, test_loss: 0.135392, test_acc: 0.950481\n",
      "epo: 34, train_loss: 0.144828, train_acc: 0.943022\n",
      "epo: 34, test_loss: 0.136806, test_acc: 0.951401\n",
      "epo: 35, train_loss: 0.144479, train_acc: 0.943902\n",
      "epo: 35, test_loss: 0.134625, test_acc: 0.951881\n",
      "epo: 36, train_loss: 0.145809, train_acc: 0.943502\n",
      "epo: 36, test_loss: 0.134688, test_acc: 0.950761\n",
      "epo: 37, train_loss: 0.154546, train_acc: 0.939021\n",
      "epo: 37, test_loss: 0.137302, test_acc: 0.950841\n",
      "epo: 38, train_loss: 0.144255, train_acc: 0.942942\n",
      "epo: 38, test_loss: 0.136745, test_acc: 0.949801\n",
      "epo: 39, train_loss: 0.143233, train_acc: 0.944662\n",
      "epo: 39, test_loss: 0.135458, test_acc: 0.951201\n",
      "epo: 40, train_loss: 0.145375, train_acc: 0.943062\n",
      "epo: 40, test_loss: 0.135827, test_acc: 0.951201\n",
      "epo: 41, train_loss: 0.142577, train_acc: 0.944262\n",
      "epo: 41, test_loss: 0.134207, test_acc: 0.951921\n",
      "epo: 42, train_loss: 0.152592, train_acc: 0.93898\n",
      "epo: 42, test_loss: 0.136888, test_acc: 0.948361\n",
      "epo: 43, train_loss: 0.144337, train_acc: 0.942862\n",
      "epo: 43, test_loss: 0.131109, test_acc: 0.949241\n",
      "epo: 44, train_loss: 0.142837, train_acc: 0.943902\n",
      "epo: 44, test_loss: 0.138937, test_acc: 0.945721\n",
      "epo: 45, train_loss: 0.16815, train_acc: 0.933539\n",
      "epo: 45, test_loss: 0.133086, test_acc: 0.951601\n",
      "epo: 46, train_loss: 0.138914, train_acc: 0.945943\n",
      "epo: 46, test_loss: 0.123876, test_acc: 0.953241\n",
      "epo: 47, train_loss: 0.137123, train_acc: 0.946943\n",
      "epo: 47, test_loss: 0.13265, test_acc: 0.948521\n",
      "epo: 48, train_loss: 0.138575, train_acc: 0.946023\n",
      "epo: 48, test_loss: 0.148707, test_acc: 0.941921\n",
      "epo: 49, train_loss: 0.13813, train_acc: 0.947103\n",
      "epo: 49, test_loss: 0.13436, test_acc: 0.950241\n",
      "epo: 50, train_loss: 0.140739, train_acc: 0.945342\n",
      "epo: 50, test_loss: 0.115384, test_acc: 0.956881\n",
      "epo: 51, train_loss: 0.136195, train_acc: 0.947263\n",
      "epo: 51, test_loss: 0.123968, test_acc: 0.955521\n",
      "epo: 52, train_loss: 0.134668, train_acc: 0.947463\n",
      "epo: 52, test_loss: 0.122711, test_acc: 0.954681\n",
      "epo: 53, train_loss: 0.135437, train_acc: 0.947103\n",
      "epo: 53, test_loss: 0.116315, test_acc: 0.955761\n",
      "epo: 54, train_loss: 0.152217, train_acc: 0.940301\n",
      "epo: 54, test_loss: 0.129871, test_acc: 0.951241\n",
      "epo: 55, train_loss: 0.139861, train_acc: 0.945623\n",
      "epo: 55, test_loss: 0.142308, test_acc: 0.944721\n",
      "epo: 56, train_loss: 0.137771, train_acc: 0.946783\n",
      "epo: 56, test_loss: 0.114, test_acc: 0.957601\n",
      "epo: 57, train_loss: 0.159067, train_acc: 0.9367\n",
      "epo: 57, test_loss: 0.120832, test_acc: 0.954761\n",
      "epo: 58, train_loss: 0.148682, train_acc: 0.941501\n",
      "epo: 58, test_loss: 0.112416, test_acc: 0.958721\n",
      "epo: 59, train_loss: 0.149492, train_acc: 0.942422\n",
      "epo: 59, test_loss: 0.126737, test_acc: 0.951081\n",
      "epo: 60, train_loss: 0.13892, train_acc: 0.945583\n",
      "epo: 60, test_loss: 0.123618, test_acc: 0.954521\n",
      "epo: 61, train_loss: 0.138143, train_acc: 0.946903\n",
      "epo: 61, test_loss: 0.114898, test_acc: 0.957841\n",
      "epo: 62, train_loss: 0.13784, train_acc: 0.946903\n",
      "epo: 62, test_loss: 0.119593, test_acc: 0.955561\n",
      "epo: 63, train_loss: 0.132025, train_acc: 0.948864\n",
      "epo: 63, test_loss: 0.116241, test_acc: 0.957401\n",
      "epo: 64, train_loss: 0.126788, train_acc: 0.951825\n",
      "epo: 64, test_loss: 0.114528, test_acc: 0.957801\n",
      "epo: 65, train_loss: 0.132832, train_acc: 0.948784\n",
      "epo: 65, test_loss: 0.113146, test_acc: 0.958921\n",
      "epo: 66, train_loss: 0.129127, train_acc: 0.949424\n",
      "epo: 66, test_loss: 0.111939, test_acc: 0.958681\n",
      "epo: 67, train_loss: 0.129891, train_acc: 0.949104\n",
      "epo: 67, test_loss: 0.117143, test_acc: 0.956561\n",
      "epo: 68, train_loss: 0.126678, train_acc: 0.951024\n",
      "epo: 68, test_loss: 0.110511, test_acc: 0.959281\n",
      "epo: 69, train_loss: 0.125706, train_acc: 0.949904\n",
      "epo: 69, test_loss: 0.107106, test_acc: 0.958921\n",
      "epo: 70, train_loss: 0.123959, train_acc: 0.951905\n",
      "epo: 70, test_loss: 0.106774, test_acc: 0.959681\n",
      "epo: 71, train_loss: 0.128178, train_acc: 0.950104\n",
      "epo: 71, test_loss: 0.106673, test_acc: 0.959161\n",
      "epo: 72, train_loss: 0.118392, train_acc: 0.954385\n",
      "epo: 72, test_loss: 0.101656, test_acc: 0.961281\n",
      "epo: 73, train_loss: 0.115393, train_acc: 0.955706\n",
      "epo: 73, test_loss: 0.10327, test_acc: 0.960121\n",
      "epo: 74, train_loss: 0.11356, train_acc: 0.956266\n",
      "epo: 74, test_loss: 0.0924849, test_acc: 0.965241\n",
      "epo: 75, train_loss: 0.126677, train_acc: 0.951745\n",
      "epo: 75, test_loss: 0.0877469, test_acc: 0.966801\n",
      "epo: 76, train_loss: 0.126313, train_acc: 0.950424\n",
      "epo: 76, test_loss: 0.0828247, test_acc: 0.969521\n",
      "epo: 77, train_loss: 0.103249, train_acc: 0.961108\n",
      "epo: 77, test_loss: 0.0900686, test_acc: 0.966721\n",
      "epo: 78, train_loss: 0.120921, train_acc: 0.953425\n",
      "epo: 78, test_loss: 0.184264, test_acc: 0.928081\n",
      "epo: 79, train_loss: 0.113124, train_acc: 0.955986\n",
      "epo: 79, test_loss: 0.0794613, test_acc: 0.971641\n",
      "epo: 80, train_loss: 0.0948236, train_acc: 0.964829\n",
      "epo: 80, test_loss: 0.0763149, test_acc: 0.973361\n",
      "epo: 81, train_loss: 0.10004, train_acc: 0.961788\n",
      "epo: 81, test_loss: 0.0669517, test_acc: 0.976321\n",
      "epo: 82, train_loss: 0.105716, train_acc: 0.958587\n",
      "epo: 82, test_loss: 0.203249, test_acc: 0.923001\n",
      "epo: 83, train_loss: 0.101679, train_acc: 0.960307\n",
      "epo: 83, test_loss: 0.0653964, test_acc: 0.976001\n",
      "epo: 84, train_loss: 0.082229, train_acc: 0.96919\n",
      "epo: 84, test_loss: 0.0631718, test_acc: 0.977681\n",
      "epo: 85, train_loss: 0.0742251, train_acc: 0.972631\n",
      "epo: 85, test_loss: 0.0610245, test_acc: 0.979281\n",
      "epo: 86, train_loss: 0.0775853, train_acc: 0.971111\n",
      "epo: 86, test_loss: 0.0584399, test_acc: 0.978961\n",
      "epo: 87, train_loss: 0.0809606, train_acc: 0.96983\n",
      "epo: 87, test_loss: 0.0685489, test_acc: 0.975441\n",
      "epo: 88, train_loss: 0.0748019, train_acc: 0.972631\n",
      "epo: 88, test_loss: 0.0567165, test_acc: 0.980321\n",
      "epo: 89, train_loss: 0.0699828, train_acc: 0.975032\n",
      "epo: 89, test_loss: 0.0582241, test_acc: 0.978801\n",
      "epo: 90, train_loss: 0.0711685, train_acc: 0.973752\n",
      "epo: 90, test_loss: 0.0593653, test_acc: 0.979481\n",
      "epo: 91, train_loss: 0.0680066, train_acc: 0.975032\n",
      "epo: 91, test_loss: 0.0554331, test_acc: 0.980961\n",
      "epo: 92, train_loss: 0.0730129, train_acc: 0.973391\n",
      "epo: 92, test_loss: 0.0566635, test_acc: 0.980681\n",
      "epo: 93, train_loss: 0.113624, train_acc: 0.956346\n",
      "epo: 93, test_loss: 0.0588388, test_acc: 0.979521\n",
      "epo: 94, train_loss: 0.0903742, train_acc: 0.965269\n",
      "epo: 94, test_loss: 0.0587085, test_acc: 0.979281\n",
      "epo: 95, train_loss: 0.0715973, train_acc: 0.973992\n",
      "epo: 95, test_loss: 0.0568639, test_acc: 0.979801\n",
      "epo: 96, train_loss: 0.0905001, train_acc: 0.965309\n",
      "epo: 96, test_loss: 0.0532782, test_acc: 0.981121\n",
      "epo: 97, train_loss: 0.061382, train_acc: 0.977153\n",
      "epo: 97, test_loss: 0.0655441, test_acc: 0.977121\n",
      "epo: 98, train_loss: 0.0679435, train_acc: 0.974392\n",
      "epo: 98, test_loss: 0.0516147, test_acc: 0.981881\n",
      "epo: 99, train_loss: 0.0642708, train_acc: 0.976192\n",
      "epo: 99, test_loss: 0.0547754, test_acc: 0.981081\n",
      "Spend 2415.12241507 sec for train and test\n"
     ]
    }
   ],
   "source": [
    "Mi = MultiRNN( args_[i], i+1 ).train_n_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
